{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38bf86bc-1bef-4b68-8f6a-c08a6d91202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/20 21:52:09 WARN Utils: Your hostname, Pavels-MacBook-Air.local resolves to a loopback address: 127.0.0.200; using 192.168.0.103 instead (on interface en0)\n",
      "23/07/20 21:52:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/20 21:52:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/07/20 21:52:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.103:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>custom_name</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff358312fb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import re\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window as W\n",
    "\n",
    "from hhop import get_spark_builder\n",
    "spark_builder = get_spark_builder('custom_name'); \n",
    "spark = spark_builder.getOrCreate(); sc = spark.sparkContext; sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "from hhop import DFExtender, SchemaManager, TablePartitionDescriber, SCD2Helper #main classes\n",
    "from hhop import read_table, write_table, write_read_table, union_all, deduplicate_df, get_table_location # useful functions\n",
    "from hhop import HhopException\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba9c62",
   "metadata": {},
   "source": [
    "## to_scd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad81453-9c1c-4d6b-acdf-66f8844858c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_transactions = spark.read.csv('../hhop/scd2_data/to_scd2.csv', sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841167a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFExtender(df1_transactions, pk=['pk1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7b6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_transactions = df1_transactions.withColumnRenamed('pk1', 'PK1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cca8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PK1: string (nullable = true)\n",
      " |-- pk2: string (nullable = true)\n",
      " |-- nonpk1: string (nullable = true)\n",
      " |-- nonpk2: string (nullable = true)\n",
      " |-- nonpk3: string (nullable = true)\n",
      " |-- nonpk_extra: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f19befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = {1,2,3}\n",
    "# k.add(*[1,2])\n",
    "# k.remove(1)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afeb7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start magic\n",
      "normal call 1\n",
      "end magic\n"
     ]
    }
   ],
   "source": [
    "def p(is_second_line):\n",
    "    def _decorator(foo, **kwargs):\n",
    "        print(**kwargs)\n",
    "        def magic( self , *args, **kwargs) :\n",
    "            print(\"start magic\")\n",
    "            foo( self , *args,is_second_line, **kwargs)\n",
    "            print(\"end magic\")\n",
    "        return magic\n",
    "    return _decorator\n",
    "\n",
    "class Test(object):\n",
    "    @p(False)\n",
    "    def bar( self , num, asdf, is_second_line) :\n",
    "        print(f\"normal call {num}\")\n",
    "        if is_second_line:\n",
    "            print('normal call 2')\n",
    "\n",
    "test = Test()\n",
    "\n",
    "test.bar(1, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40d75d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DFColCleaner:\n",
    "    \"\"\"WIP\n",
    "    Helps with comparing and raising exceptions on columns of DFs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, **group_cols):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Raises:\n",
    "            HhopException: _description_\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "        df_columns = self.lower_list(self.df.columns)\n",
    "        # will throw an exception on duplicated groups\n",
    "        _ = self.lower_list(group_cols.keys(), type_error='column groups') \n",
    "\n",
    "        all_columns_set = set(df_columns) # for N(1) check of entry\n",
    "        not_in_all_columns = set() # raise error if not empty\n",
    "        group_cols_clean = {} # new dict with lower columns and groups\n",
    "        for group, cols in group_cols.items():\n",
    "            group = group.lower()\n",
    "            columns_in_group = []\n",
    "            for column in cols:\n",
    "                column = column.lower()\n",
    "                if column not in all_columns_set:\n",
    "                    not_in_all_columns.add(column)\n",
    "                columns_in_group.append(column)\n",
    "            group_cols_clean[group] = self.lower_list(columns_in_group)\n",
    "        if not_in_all_columns:\n",
    "            raise HhopException(f\"Columns {not_in_all_columns} not in the DF: {df_columns}\")\n",
    "        \n",
    "        # this adds groups: all and extra\n",
    "        group_cols_clean = {str.lower(group): [str.lower(column) for column in cols] for group, cols in group_cols_clean.items()} # to lower columns in groups\n",
    "        group_cols_clean['all'] = df_columns\n",
    "        group_cols_clean['extra'] = list(set(df_columns) - set([c for cg in group_cols_clean for c in group_cols_clean[cg] if cg != 'all']))\n",
    "        self.group_cols = group_cols_clean\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def lower_list(cols, type_error=\"columns\"):\n",
    "        lower_list = [str.lower(elem) for elem in cols]\n",
    "        seen = set()\n",
    "        dupes = [x for x in lower_list if x in seen or seen.add(x)]\n",
    "        if dupes:\n",
    "            raise HhopException(f\"Found duplicates {type_error}: {dupes}\")\n",
    "\n",
    "        return lower_list\n",
    "\n",
    "    def mass_rename(self, suffix, is_append_suffix, group_cols_include=None, group_cols_exclude=None):\n",
    "\n",
    "        cols_to_rename = self.get_columns_from_groups(group_cols_include, group_cols_exclude)\n",
    "        dict_rename = {}\n",
    "        if is_append_suffix:\n",
    "            new_colname = lambda x: x + suffix\n",
    "        else:\n",
    "            new_colname = lambda x: re.sub(fr'{suffix}$', '', x)\n",
    "        for column in cols_to_rename:\n",
    "            dict_rename[column] = new_colname(column)\n",
    "            # print(column, new_colname(column))\n",
    "\n",
    "        df = self.rename_to(self.df, dict_rename)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def rename_to(df, old_new_mapping: dict):\n",
    "        for old, new in old_new_mapping.items():\n",
    "            df = df.withColumnRenamed(old, new)\n",
    "        return df\n",
    "\n",
    "    def get_columns_from_groups(self, group_cols_include=None, group_cols_exclude=None) -> set:\n",
    "        group_cols_include = self.lower_list(group_cols_include or ['all'], type_error='column groups')  # all is default\n",
    "        group_cols_exclude = self.lower_list(group_cols_exclude or [], type_error='column groups') \n",
    "        cols_out = set()\n",
    "        for gc_include in group_cols_include:\n",
    "            _ = [cols_out.add(column) for column in self.group_cols[gc_include]]\n",
    "            for gc_exclude in group_cols_exclude:\n",
    "                for column in self.group_cols[gc_exclude]:\n",
    "                    try:\n",
    "                        cols_out.remove(column)\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "        return cols_out\n",
    "\n",
    "    @classmethod\n",
    "    def get_columns_with_suffix(cls, df, suffix):\n",
    "        df_cols = cls.lower_list(df.columns)\n",
    "        cols_with_suffix = []\n",
    "        for column in df_cols:\n",
    "            if re.match(rf\"[\\w_\\d]+{suffix}$\", column):\n",
    "                cols_with_suffix.append(column)\n",
    "        return cols_with_suffix\n",
    "\n",
    "    def is_cols_subset(self, cols, group_cols_include=None, group_cols_exclude=None) -> bool:\n",
    "        cols_in_groups = self.get_columns_from_groups(group_cols_include, group_cols_exclude)\n",
    "        cols_left = set(cols) - cols_in_groups\n",
    "        return len(cols_left) == 0\n",
    "\n",
    "\n",
    "\n",
    "class DFColValidator:\n",
    "    \"To validate 2 dataframes from class DFColCleaner\"\n",
    "\n",
    "    def __init__(self, obj1, obj2) -> None:\n",
    "        self.obj1 = obj1\n",
    "        self.obj2 = obj2\n",
    "\n",
    "    def _get_cols_on_groups(self, group_cols_include=None, group_cols_exclude=None):\n",
    "        cols1 = self.obj1.get_columns_from_groups(\n",
    "            group_cols_include, group_cols_exclude\n",
    "        )\n",
    "        cols2 = self.obj2.get_columns_from_groups(\n",
    "            group_cols_include, group_cols_exclude\n",
    "        )\n",
    "        return cols1, cols2\n",
    "    \n",
    "\n",
    "    def _compare_groups(\n",
    "        self, operator, group_cols_include=None, group_cols_exclude=None\n",
    "    ):\n",
    "        cols1, cols2 = self._get_cols_on_groups(group_cols_include, group_cols_exclude)\n",
    "        return operator(cols1, cols2)\n",
    "\n",
    "    # this looks like something can be done to simplify methods\n",
    "    def get_intersection_groups(self, group_cols_include=None, group_cols_exclude=None):\n",
    "        return self._compare_groups(\n",
    "            set.intersection,\n",
    "            group_cols_include=group_cols_include,\n",
    "            group_cols_exclude=group_cols_exclude,\n",
    "        )\n",
    "\n",
    "    def get_union_groups(self, group_cols_include=None, group_cols_exclude=None):\n",
    "        return self._compare_groups(\n",
    "            set.union,\n",
    "            group_cols_include=group_cols_include,\n",
    "            group_cols_exclude=group_cols_exclude,\n",
    "        )\n",
    "\n",
    "    def get_xor_groups(self, group_cols_include=None, group_cols_exclude=None):\n",
    "        return self._compare_groups(\n",
    "            set.__xor__,\n",
    "            group_cols_include=group_cols_include,\n",
    "            group_cols_exclude=group_cols_exclude,\n",
    "        )\n",
    "\n",
    "    def is_equal_cols_groups(self, group_cols_include=None, group_cols_exclude=None):\n",
    "        return len(self.get_xor_groups(group_cols_include, group_cols_exclude)) == 0\n",
    "\n",
    "c1 = DFColCleaner(df1_transactions, PK=['pK2'], s=['nonpK3', 'pk1'])\n",
    "c2 = DFColCleaner(df1_transactions.drop('pk1'), PK=['pK2'], s=['nonpK3', 'pk2'])\n",
    "\n",
    "k = DFColValidator(c1, c2)\n",
    "# k.get_intersection_groups()\n",
    "# k.get_xor_groups() # is it required to be kwargs?\n",
    "k.is_equal_cols_groups(['pk'])\n",
    "c = DFColCleaner(df1_transactions, PK=['pK2'], s=['nonpK3', 'pk1'])\n",
    "df1 = c.mass_rename('_asdf', True, group_cols_include=['all'], group_cols_exclude=['pK'])\n",
    "df1\n",
    "c.get_columns_with_suffix(df1, 'df1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = '5_asdf'\n",
    "bool(re.match(rf\"[\\w_\\d]+{suffix}$\", 'col5_asdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580266a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c = DFColCleaner(df1_transactions, PK=['pK2'], s=['nonpK3', 'pk1'])\n",
    "# df1 = c.mass_rename('_asdf', True, group_cols_include=['all'], group_cols_exclude=['pK'])\n",
    "# c1 = DFCleaner(df1, PK=['pK1'], s=['nonpK3_asdf'])\n",
    "# c1.mass_rename('_asdf', False, group_cols_include=['all'])\n",
    "# c.get_columns_from_groups(['pk'])\n",
    "# print(c.group_cols)\n",
    "# c.is_cols_subset(['pk3'], ['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4f00331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pk2', 'pk1'}\n",
      "+---+---+\n",
      "|pk2|pk1|\n",
      "+---+---+\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "|c1 |v1 |\n",
      "+---+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ll = ['pk1', 'pk2']\n",
    "ll = set(ll)\n",
    "print(ll)\n",
    "df1_transactions.select(*ll).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2e6531-2c80-4690-888e-61eb292d3b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |\n",
      "+---+----+------+------+------+-----------+-------------------+\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|\n",
      "|v1 |c1  |a1    |b1    |c1    |r2         |2023-05-01 12:00:00|\n",
      "|v1 |c1  |a1    |b1    |c1    |r3         |2023-05-02 12:00:00|\n",
      "|v1 |c1  |a1    |b1    |c2    |null       |2023-05-03 12:00:00|\n",
      "|v1 |c1  |a1    |b2    |c2    |null       |2023-05-03 15:00:00|\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-06 15:00:00|\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-07 15:00:00|\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-13 15:00:00|\n",
      "+---+----+------+------+------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_transactions.orderBy(['pk1', 'pk2', 'ts']).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3993c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_transactions_s = SCD2Helper(\n",
    "    df1_transactions, \n",
    "    pk=['pk1', 'pk2'], \n",
    "    non_pk=['nonpk1', 'nonpk2', 'nonpk3'],\n",
    "    time_col='ts',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e84d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_scd2 = df1_transactions_s.df_to_scd2().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa43c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|56e6807f4b745e20dffeb1b731e5a6d4|2023-05-07     |2023-05-09   |\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-10     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |2023-05-11   |\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|b08363345cd7c1cb14e6f4747ce1563d|2023-05-12     |9999-12-31   |\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|93e6cc4b8b0445cf261e9417106ae6f0|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |a1    |b2    |c2    |null       |2023-05-03 15:00:00|a6244d3c7c2aed33c4d9525fbef29c1d|2023-05-03     |2023-05-04   |\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|17f599be9e07976c2036361c9ad8f633|2023-05-05     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-07 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-07     |2023-05-09   |\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-10     |2023-05-12   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-13 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-13     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2.orderBy(['pk1', 'pk2', 'ts']).show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012f7bd",
   "metadata": {},
   "source": [
    "## validate_scd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c0093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pk1: string (nullable = true)\n",
      " |-- pk2: string (nullable = true)\n",
      " |-- nonpk1: string (nullable = true)\n",
      " |-- nonpk2: string (nullable = true)\n",
      " |-- nonpk3: string (nullable = true)\n",
      " |-- nonpk_extra: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      " |-- row_hash: string (nullable = false)\n",
      " |-- row_actual_from: string (nullable = true)\n",
      " |-- row_actual_to: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd54af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 10\n",
      "All tests passed\n",
      "Errors_In_SCD2_table(duplicates_by_pk=0, invalid_dates=0, broken_history=0, duplicates_by_version=0) 0 0\n"
     ]
    }
   ],
   "source": [
    "res = df1_scd2.validate_scd2()\n",
    "print(res, res[0], res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aefdf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 PK duplicates by ['pk1', 'pk2', 'row_actual_to'] Look at `.basic_pk_check.df_duplicates_pk`\n",
      "10 rows with invalid dates, look at `.df_invalid_dates`\n",
      "Number of records: 10\n",
      "Errors_In_SCD2_table(duplicates_by_pk=2, invalid_dates=10, broken_history=0, duplicates_by_version=0) 2 0\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_wrong_copy = SCD2Helper(\n",
    "    df1_scd2.withColumn('row_actual_to', F.when(col('row_actual_to') == '9999-12-31', F.lit('1000-01-01'))), \n",
    "    pk=['pk1', 'pk2'], \n",
    "    non_pk=['nonpk1', 'nonpk2', 'nonpk3'],\n",
    "    time_col='ts',\n",
    ")\n",
    "res = df1_scd2_wrong_copy.validate_scd2()\n",
    "print(res, res[0], res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82721640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------+---------------+-------------+---------------+-------------+-------------------+\n",
      "|pk1| pk2|nonpk1|nonpk2|nonpk3|nonpk_extra|                 ts|            row_hash|row_actual_from|row_actual_to|valid_date_from|valid_date_to|incorrect_direction|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------+---------------+-------------+---------------+-------------+-------------------+\n",
      "| v1|  c1|    a1|    b1|    c1|         r1|2023-05-01 10:00:00|93e6cc4b8b0445cf2...|     2023-05-01|         null|           true|        false|              false|\n",
      "| v1|  c1|    a1|    b2|    c2|       null|2023-05-03 15:00:00|a6244d3c7c2aed33c...|     2023-05-03|         null|           true|        false|              false|\n",
      "| v1|  c1|  null|    b2|    c2|         r3|2023-05-05 15:00:00|17f599be9e07976c2...|     2023-05-05|         null|           true|        false|              false|\n",
      "| v1|  c1|  null|  null|    c2|         r3|2023-05-07 15:00:00|a363a9dd6d5b30865...|     2023-05-07|         null|           true|        false|              false|\n",
      "| v1|  c1|  null|  null|  null|       null|2023-05-10 15:00:00|da58ea33b20d82042...|     2023-05-10|         null|           true|        false|              false|\n",
      "| v1|  c1|  null|  null|    c2|         r3|2023-05-13 15:00:00|a363a9dd6d5b30865...|     2023-05-13|   1000-01-01|           true|         true|               true|\n",
      "| v1|null|  null|  null|    c2|         r3|2023-05-07 15:00:00|56e6807f4b745e20d...|     2023-05-07|         null|           true|        false|              false|\n",
      "| v1|null|  null|  null|  null|       null|2023-05-10 15:00:00|6654c734ccab8f440...|     2023-05-10|         null|           true|        false|              false|\n",
      "| v1|null|  null|   fds|  null|       null|2023-05-11 15:00:00|2d2722576095dd799...|     2023-05-11|         null|           true|        false|              false|\n",
      "| v1|null|  null|   fds|  asdf|       null|2023-05-12 15:00:00|b08363345cd7c1cb1...|     2023-05-12|   1000-01-01|           true|         true|               true|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------+---------------+-------------+---------------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_wrong_copy.df_invalid_dates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96821dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hhop\n",
    "reload(hhop)\n",
    "reload(hhop.hhop)\n",
    "reload(hhop.hhop.main)\n",
    "import hhop\n",
    "reload(hhop)\n",
    "reload(hhop.hhop)\n",
    "reload(hhop.hhop.main)\n",
    "from hhop import SCD2Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e9c61",
   "metadata": {},
   "source": [
    "## Fill history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bb322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|93e6cc4b8b0445cf261e9417106ae6f0|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |a1    |b2    |c2    |null       |2023-05-03 15:00:00|a6244d3c7c2aed33c4d9525fbef29c1d|2023-05-03     |2023-05-04   |\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|17f599be9e07976c2036361c9ad8f633|2023-05-05     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-07 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-07     |2023-05-09   |\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-10     |2023-05-12   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-13 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-13     |9999-12-31   |\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|56e6807f4b745e20dffeb1b731e5a6d4|2023-05-07     |2023-05-09   |\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-10     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |2023-05-11   |\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|b08363345cd7c1cb14e6f4747ce1563d|2023-05-12     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00aedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|93e6cc4b8b0445cf261e9417106ae6f0|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|17f599be9e07976c2036361c9ad8f633|2023-05-05     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-10     |2023-05-12   |\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|56e6807f4b745e20dffeb1b731e5a6d4|2023-05-07     |2023-05-09   |\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-10     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |2023-05-11   |\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|b08363345cd7c1cb14e6f4747ce1563d|2023-05-12     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_add_more_holes = SCD2Helper(\n",
    "    df1_scd2.filter(~col('row_hash').isin(\"a363a9dd6d5b30865ab5813581941516\", 'a363a9dd6d5b30865ab5813581941516', 'a6244d3c7c2aed33c4d9525fbef29c1d')), \n",
    "    pk=['pk1', 'pk2'], \n",
    "    non_pk=['nonpk1', 'nonpk2', 'nonpk3'],\n",
    ")\n",
    "df1_scd2_add_more_holes.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921bafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |null|null  |null  |null  |null       |null               |56e6807f4b745e20dffeb1b731e5a6d4|1000-01-01     |2023-05-06   |\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|56e6807f4b745e20dffeb1b731e5a6d4|2023-05-07     |2023-05-09   |\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-10     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |2023-05-11   |\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|b08363345cd7c1cb14e6f4747ce1563d|2023-05-12     |9999-12-31   |\n",
      "|v1 |c1  |null  |null  |null  |null       |null               |93e6cc4b8b0445cf261e9417106ae6f0|1000-01-01     |2023-04-30   |\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|93e6cc4b8b0445cf261e9417106ae6f0|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |null  |null  |null  |null       |null               |17f599be9e07976c2036361c9ad8f633|2023-05-03     |2023-05-04   |\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|17f599be9e07976c2036361c9ad8f633|2023-05-05     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |null  |null       |null               |da58ea33b20d82042d9969c46c16c3b8|2023-05-07     |2023-05-09   |\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-10     |2023-05-12   |\n",
      "|v1 |c1  |null  |null  |null  |null       |null               |da58ea33b20d82042d9969c46c16c3b8|2023-05-13     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_filled_history = df1_scd2_add_more_holes.fill_scd2_history()\n",
    "df1_filled_history.orderBy(['pk1', 'pk2', 'row_actual_from']).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cfd15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_col is not provided, checking duplicated versions is skipped\n",
      "Number of records: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Errors_In_SCD2_table(duplicates_by_pk=0, invalid_dates=0, broken_history=0, duplicates_by_version=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_filled_history.validate_scd2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcdbde",
   "metadata": {},
   "source": [
    "## merge scd2 history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8209bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_scd2_fewer_non_pk = SCD2Helper(\n",
    "    df1_scd2,\n",
    "    pk=['pk1', 'pk2'], \n",
    "    non_pk=['nonpk2'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67de5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_merged_history = df1_scd2_fewer_non_pk.merge_scd2_history().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76596606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|56e6807f4b745e20dffeb1b731e5a6d4|2023-05-07     |2023-05-09   |\n",
      "|v1 |null|null  |null  |null  |null       |2023-05-10 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-10     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |2023-05-11   |\n",
      "|v1 |null|null  |fds   |asdf  |null       |2023-05-12 15:00:00|b08363345cd7c1cb14e6f4747ce1563d|2023-05-12     |9999-12-31   |\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|93e6cc4b8b0445cf261e9417106ae6f0|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |a1    |b2    |c2    |null       |2023-05-03 15:00:00|a6244d3c7c2aed33c4d9525fbef29c1d|2023-05-03     |2023-05-04   |\n",
      "|v1 |c1  |null  |b2    |c2    |r3         |2023-05-05 15:00:00|17f599be9e07976c2036361c9ad8f633|2023-05-05     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-07 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-07     |2023-05-09   |\n",
      "|v1 |c1  |null  |null  |null  |null       |2023-05-10 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-10     |2023-05-12   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-13 15:00:00|a363a9dd6d5b30865ab5813581941516|2023-05-13     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2.orderBy('pk1', 'pk2', 'row_actual_from').show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc816916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2 |nonpk1|nonpk2|nonpk3|nonpk_extra|ts                 |row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "|v1 |null|null  |null  |c2    |r3         |2023-05-07 15:00:00|6654c734ccab8f440ff0825eb443dc7f|2023-05-07     |2023-05-10   |\n",
      "|v1 |null|null  |fds   |null  |null       |2023-05-11 15:00:00|2d2722576095dd7996570b307d777539|2023-05-11     |9999-12-31   |\n",
      "|v1 |c1  |a1    |b1    |c1    |r1         |2023-05-01 10:00:00|096c3c37214aa93e8c988eddef82cf00|2023-05-01     |2023-05-02   |\n",
      "|v1 |c1  |a1    |b2    |c2    |null       |2023-05-03 15:00:00|e3a0efcb4f913e410841e9a50cc55b0b|2023-05-03     |2023-05-06   |\n",
      "|v1 |c1  |null  |null  |c2    |r3         |2023-05-07 15:00:00|da58ea33b20d82042d9969c46c16c3b8|2023-05-07     |9999-12-31   |\n",
      "+---+----+------+------+------+-----------+-------------------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_merged_history.orderBy('pk1', 'pk2', 'row_actual_from').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9c95c",
   "metadata": {},
   "source": [
    "## join scd2 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35dde350-b242-495f-866a-fcc20fb47a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = [spark.read.csv(f'../hhop/scd2_data/df_scd2_join_{i}.csv', sep=';', header=True) for i in range(1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1790de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+-------------------+\n",
      "|pk1|pk2|email_id|ts                 |\n",
      "+---+---+--------+-------------------+\n",
      "|v1 |c1 |e1      |2023-05-01 10:00:00|\n",
      "|v1 |c1 |e2      |2023-05-04 12:00:00|\n",
      "|v1 |c1 |e3      |2023-05-10 12:00:00|\n",
      "|v1 |c1 |e1      |2023-05-12 12:00:00|\n",
      "|v1 |c2 |e1      |2023-05-01 10:00:00|\n",
      "|v1 |c3 |e2      |2023-05-04 12:00:00|\n",
      "|v1 |c3 |e3      |2023-05-10 12:00:00|\n",
      "|v1 |c3 |e1      |2023-05-12 12:00:00|\n",
      "+---+---+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43ae19a-c9fc-4025-8abb-626b2d5da4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+-------------------+\n",
      "|pk1|pk2|phone_id|ts                 |\n",
      "+---+---+--------+-------------------+\n",
      "|v1 |c1 |e1      |2023-04-01 10:00:00|\n",
      "|v1 |c1 |e2      |2023-05-06 12:00:00|\n",
      "|v1 |c1 |e3      |2023-05-12 12:00:00|\n",
      "|v1 |c1 |e1      |2023-05-13 12:00:00|\n",
      "|v1 |c2 |e1      |2023-04-01 10:00:00|\n",
      "|v1 |c2 |e2      |2023-05-06 12:00:00|\n",
      "|v1 |c2 |e3      |2023-05-12 12:00:00|\n",
      "|v1 |c2 |e1      |2023-05-13 12:00:00|\n",
      "+---+---+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f67671-94d3-4575-8176-2d8e37dcc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_scd2_j, df2_scd2_j = [SCD2Helper(df, ['pk1', 'pk2'], [non_pk_col], 'ts').df_to_scd2().cache() for df, non_pk_col in zip((df1, df2), ('email_id', 'phone_id'))]\n",
    "df1_scd2_j, df2_scd2_j = [SCD2Helper(df.drop('ts'), ['pk1', 'pk2'], [non_pk_col], 'ts') for df, non_pk_col in zip((df1_scd2_j, df2_scd2_j),('email_id', 'phone_id'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74157139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+--------------------+---------------+-------------+\n",
      "|pk1|pk2|email_id|            row_hash|row_actual_from|row_actual_to|\n",
      "+---+---+--------+--------------------+---------------+-------------+\n",
      "| v1| c1|      e1|e14f0e80db49cd150...|     2023-05-01|   2023-05-03|\n",
      "| v1| c1|      e2|9862c1fb9265b0369...|     2023-05-04|   2023-05-09|\n",
      "| v1| c1|      e3|543b4e1fe15d3cd37...|     2023-05-10|   2023-05-11|\n",
      "| v1| c1|      e1|e14f0e80db49cd150...|     2023-05-12|   9999-12-31|\n",
      "| v1| c3|      e2|5f5d71094a0572ea7...|     2023-05-04|   2023-05-09|\n",
      "| v1| c3|      e3|9743390e49e720967...|     2023-05-10|   2023-05-11|\n",
      "| v1| c3|      e1|796f048cc1ff82db2...|     2023-05-12|   9999-12-31|\n",
      "| v1| c2|      e1|db078b8d7b629e8c3...|     2023-05-01|   9999-12-31|\n",
      "+---+---+--------+--------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_j.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b0ac168-a2d1-40ef-a79f-abc0e783f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+--------------------------------+---------------+-------------+\n",
      "|pk1|pk2|phone_id|row_hash                        |row_actual_from|row_actual_to|\n",
      "+---+---+--------+--------------------------------+---------------+-------------+\n",
      "|v1 |c1 |e1      |e14f0e80db49cd1501de87adf05f6022|2023-04-01     |2023-05-05   |\n",
      "|v1 |c1 |e2      |9862c1fb9265b03695dc9a727406c43e|2023-05-06     |2023-05-11   |\n",
      "|v1 |c1 |e3      |543b4e1fe15d3cd37fc7b9454156f4e1|2023-05-12     |2023-05-12   |\n",
      "|v1 |c1 |e1      |e14f0e80db49cd1501de87adf05f6022|2023-05-13     |9999-12-31   |\n",
      "|v1 |c2 |e1      |db078b8d7b629e8c3e11aeaf24952480|2023-04-01     |2023-05-05   |\n",
      "|v1 |c2 |e2      |284ed4afc0045d818e840896714656ca|2023-05-06     |2023-05-11   |\n",
      "|v1 |c2 |e3      |87795052bb06129a6007a0dfaad2efef|2023-05-12     |2023-05-12   |\n",
      "|v1 |c2 |e1      |db078b8d7b629e8c3e11aeaf24952480|2023-05-13     |9999-12-31   |\n",
      "+---+---+--------+--------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_scd2_j.show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f1e8f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+--------+---------------+-------------+\n",
      "|pk1|pk2|email_id|phone_id|row_actual_from|row_actual_to|\n",
      "+---+---+--------+--------+---------------+-------------+\n",
      "|v1 |c1 |e1      |e1      |2023-05-01     |2023-05-03   |\n",
      "|v1 |c1 |e2      |e1      |2023-05-04     |2023-05-05   |\n",
      "|v1 |c1 |e2      |e2      |2023-05-06     |2023-05-09   |\n",
      "|v1 |c1 |e3      |e2      |2023-05-10     |2023-05-11   |\n",
      "|v1 |c1 |e1      |e3      |2023-05-12     |2023-05-12   |\n",
      "|v1 |c1 |e1      |e1      |2023-05-13     |9999-12-31   |\n",
      "|v1 |c2 |e1      |e1      |2023-05-01     |2023-05-05   |\n",
      "|v1 |c2 |e1      |e2      |2023-05-06     |2023-05-11   |\n",
      "|v1 |c2 |e1      |e3      |2023-05-12     |2023-05-12   |\n",
      "|v1 |c2 |e1      |e1      |2023-05-13     |9999-12-31   |\n",
      "|v1 |c3 |e2      |null    |2023-05-04     |2023-05-09   |\n",
      "|v1 |c3 |e3      |null    |2023-05-10     |2023-05-11   |\n",
      "|v1 |c3 |e1      |null    |2023-05-12     |9999-12-31   |\n",
      "+---+---+--------+--------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_j.join_scd2(df2_scd2_j).orderBy('pk1', 'pk2', 'row_actual_from').show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51cf45",
   "metadata": {},
   "source": [
    "join with filled history, however I recommend to cache or write this dataframes to HDFS if they are too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec98ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+--------+---------------+-------------+\n",
      "|pk1|pk2|email_id|phone_id|row_actual_from|row_actual_to|\n",
      "+---+---+--------+--------+---------------+-------------+\n",
      "|v1 |c1 |null    |null    |1000-01-01     |2023-03-31   |\n",
      "|v1 |c1 |null    |e1      |2023-04-01     |2023-04-30   |\n",
      "|v1 |c1 |e1      |e1      |2023-05-01     |2023-05-03   |\n",
      "|v1 |c1 |e2      |e1      |2023-05-04     |2023-05-05   |\n",
      "|v1 |c1 |e2      |e2      |2023-05-06     |2023-05-09   |\n",
      "|v1 |c1 |e3      |e2      |2023-05-10     |2023-05-11   |\n",
      "|v1 |c1 |e1      |e3      |2023-05-12     |2023-05-12   |\n",
      "|v1 |c1 |e1      |e1      |2023-05-13     |9999-12-31   |\n",
      "|v1 |c2 |null    |null    |1000-01-01     |2023-03-31   |\n",
      "|v1 |c2 |null    |e1      |2023-04-01     |2023-04-30   |\n",
      "|v1 |c2 |e1      |e1      |2023-05-01     |2023-05-05   |\n",
      "|v1 |c2 |e1      |e2      |2023-05-06     |2023-05-11   |\n",
      "|v1 |c2 |e1      |e3      |2023-05-12     |2023-05-12   |\n",
      "|v1 |c2 |e1      |e1      |2023-05-13     |9999-12-31   |\n",
      "|v1 |c3 |null    |null    |1000-01-01     |2023-05-03   |\n",
      "|v1 |c3 |e2      |null    |2023-05-04     |2023-05-09   |\n",
      "|v1 |c3 |e3      |null    |2023-05-10     |2023-05-11   |\n",
      "|v1 |c3 |e1      |null    |2023-05-12     |9999-12-31   |\n",
      "+---+---+--------+--------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_scd2_j.fill_scd2_history().join_scd2(df2_scd2_j.fill_scd2_history()).orderBy('pk1', 'pk2', 'row_actual_from').show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cee56e",
   "metadata": {},
   "source": [
    "## merge SCD2 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bcaaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50d6db1a-5890-4dcf-a92c-83ea128d88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
