# HiveHelper_on_PySpark
 Very specific, but time-saving library

## TODO
- [x] Setup local PySpark with Hive
- [x] Synth table with partitions
- [x] Basic testing script (testing inside .ipynb)
- [x] How to extend Pyspark
- [x] Finish DFExtender
- [x] Finish SchemaManager
- [x] Finish comparing tables
- [ ] Finish extra, reading from Hive, writing to Hive
- [ ] Validate on a Production cluster
- [ ] Refactoring
- [ ] Good documentation
- [ ] Second .ipynb without all testing cases (or better solution?)

## Features
1. Getting extensive info about a table
2. Comparing a table with a reference table by PK
3. Getting info about schemas and tables in a schema. Cleaning old tables.
4. Validating and getting stats on a table.
5. Simplifying operations like reading, writing Hive tables.

## Classes

### DFExtender

Description  

Available methods:

### SchemaManager

Description

Available methods: 

## Demonstration of features

### [Demo script](https://github.com/pyrogn/HiveHelper_on_PySpark/blob/main/demo.ipynb)

### [Code](https://github.com/pyrogn/HiveHelper_on_PySpark/tree/main/hhop)
